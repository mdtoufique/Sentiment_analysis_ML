{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ea1dbc-1c0a-4fe4-80ce-c1f821bef21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is my project for movie sentiment analysis. \n",
    "#i will be using NAIVE-BAYES THEOREM(A simplified version of the Bayes Theorem, known as the Naive Bayes Classification) to make the prediction\n",
    "#the steps will be 1)text pre procesing , 1)vectorizing , 3)training the mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75865e76-37b2-42c4-b5ef-754d114d691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7fc40d-4a82-4982-921c-5d5a93cb1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "df['sentiment'].replace({'positive':1,'negative':0},inplace=True)\n",
    "df.head()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_test = df.tail(1000).copy()\n",
    "Y_test=X_test.iloc[:,-1].values\n",
    "Y_result=np.zeros(1000)\n",
    "ind=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dea2cc-dfe0-4c79-8b89-3fa90291bcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350ec3fb-cb74-4e64-b5ae-c680517a0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for text processingn i will follow these steps\n",
    "#remove html tag\n",
    "#remove special char\n",
    "#covert all to lower\n",
    "#remove stop word\n",
    "#stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98476fe-a02c-4dac-8a77-c62da00429b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.head(49000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4c58fe-3b5a-4faf-b190-9f530213d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c0eb9d-72c1-4c3e-877d-227799a9025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text):\n",
    "    clean=re.compile('<.*?>')\n",
    "    return re.sub(clean,'',text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc641f6-31e8-4802-94ec-a6cde4ac190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_low(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945a3486-949e-4a2c-987b-e85f13ae51e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special(text):\n",
    "    x=''\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            x=x+i\n",
    "        else:\n",
    "            x=x+' '\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a6b1fa-8a2f-4b66-8b35-fe0b9c2c457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfc413c5-cd24-4d23-934e-d0d6ef5ec4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopper(text):\n",
    "    x=[]\n",
    "    for i in text.split():\n",
    "        if i not in stopwords.words('english'):\n",
    "            x.append(i)\n",
    "    y=x[:]\n",
    "    x.clear()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a45ec2-84bb-44b7-9b47-f7ab6eb35a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "843b852b-b866-4527-9575-b75c5d19e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "def stem_words(text):\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    z=y[:]\n",
    "    y.clear()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d8c5de6-25e5-4691-abee-e7cbda52104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_back(list_input):\n",
    "    return \" \".join(list_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1faab9-0444-4a38-bfdd-7a03fdce621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(clean_html)\n",
    "df['review']=df['review'].apply(convert_low)\n",
    "df['review']=df['review'].apply(remove_special)\n",
    "df['review']=df['review'].apply(remove_stopper)\n",
    "df['review']=df['review'].apply(stem_words)\n",
    "df['review']=df['review'].apply(join_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4879ab9-26ec-4efe-a539-0a6e5c4027ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch 1 oz episod hook righ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48995</th>\n",
       "      <td>recent saw movi first time enjoy much went rig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48996</th>\n",
       "      <td>film seen anybodi interest effect suffer eat d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48997</th>\n",
       "      <td>person disdain jerri springer show howev found...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48998</th>\n",
       "      <td>georg lopez never caught interest stand comedi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48999</th>\n",
       "      <td>agre mani review great film even better novel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      one review mention watch 1 oz episod hook righ...          1\n",
       "1      wonder littl product film techniqu unassum old...          1\n",
       "2      thought wonder way spend time hot summer weeke...          1\n",
       "3      basic famili littl boy jake think zombi closet...          0\n",
       "4      petter mattei love time money visual stun film...          1\n",
       "...                                                  ...        ...\n",
       "48995  recent saw movi first time enjoy much went rig...          1\n",
       "48996  film seen anybodi interest effect suffer eat d...          1\n",
       "48997  person disdain jerri springer show howev found...          1\n",
       "48998  georg lopez never caught interest stand comedi...          1\n",
       "48999  agre mani review great film even better novel ...          1\n",
       "\n",
       "[49000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d015247b-19dc-4e44-8941-942f97c81fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df.iloc[:,0:1].values\n",
    "#print(X)\n",
    "#X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78eb3b7-3bf5-43f0-99b5-cc69ea4b4129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85eacfad-24c0-48f3-ae04-45dff73abadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = df['review'].str.split().explode().unique().tolist()\n",
    "\n",
    "word_counts = df['review'].str.split().explode().value_counts()\n",
    "top_10000_words = word_counts.head(10000).index.tolist()\n",
    "\n",
    "\n",
    "#print(unique_words)\n",
    "conditional_prob = {None: {0: None, 1: None}}\n",
    "\n",
    "\n",
    "positive_reviews = df[df['sentiment'] == 1]\n",
    "\n",
    "total_positive_words = positive_reviews['review'].str.split().apply(len).sum()\n",
    "#print(f'Total number of words in positive reviews: {total_positive_words}')\n",
    "\n",
    "top_words_maskp = positive_reviews['review'].str.split().explode().isin(top_10000_words)\n",
    "#print(top_words_maskp.value_counts())\n",
    "top_10_p=top_words_maskp.sum();\n",
    "\n",
    "pu = positive_reviews['review'].str.split().explode().unique().tolist()\n",
    "pu = [word for word in pu if word in top_10000_words]\n",
    "cla_p=len(pu)\n",
    "\n",
    "negative_reviews = df[df['sentiment'] == 0]\n",
    "total_negative_words = negative_reviews['review'].str.split().apply(len).sum()\n",
    "#print(f'Total number of words in negative reviews: {total_negative_words}')\n",
    "\n",
    "top_words_maskn = negative_reviews['review'].str.split().explode().isin(top_10000_words)\n",
    "#print(top_words_maskn.value_counts())\n",
    "top_10_n=top_words_maskn.sum();\n",
    "\n",
    "nu = negative_reviews['review'].str.split().explode().unique().tolist()\n",
    "nu = [word for word in nu if word in top_10000_words]\n",
    "cla_n=len(nu)\n",
    "\n",
    "\n",
    "\n",
    "for specific_word in top_10000_words:\n",
    "    \n",
    "    conditional_prob[specific_word] = {0: None, 1: None}\n",
    "    \n",
    "    word_count = positive_reviews['review'].str.count(specific_word).sum()\n",
    "    conditional_prob[specific_word][1]=(word_count+1)/(top_10_p+cla_p)\n",
    "    \n",
    "    word_count = negative_reviews['review'].str.count(specific_word).sum()\n",
    "    conditional_prob[specific_word][0]=(word_count+1)/(top_10_n+cla_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e484b8-6972-44c7-ba97-2457cf7867ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(conditional_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a659d3a2-2584-46d8-acf0-7270a64b288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bayes(s):\n",
    "    \n",
    "    s=clean_html(s)\n",
    "    s=convert_low(s)\n",
    "    s=remove_special(s)\n",
    "    s=remove_stopper(s)\n",
    "    s=stem_words(s)\n",
    "    #print(s)\n",
    "\n",
    "    total_count = df.shape[0]  \n",
    "    pos_count = df['sentiment'].sum()  \n",
    "\n",
    "    prob_pos = pos_count / total_count\n",
    "    prob_neg = 1 - prob_pos  \n",
    "\n",
    "    pos=math.log(prob_pos)\n",
    "\n",
    "    neg=math.log(prob_neg)\n",
    "\n",
    "\n",
    "    for i in s:\n",
    "        if i in conditional_prob:\n",
    "            pos=pos+math.log(conditional_prob[i][1])\n",
    "            neg=neg+math.log(conditional_prob[i][0])\n",
    "    global ind\n",
    "    if(pos>=neg):\n",
    "        Y_result[ind]=1\n",
    "    ind=ind+1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "858c79c0-7155-4792-92f0-2e6242fa3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['review'].apply(bayes)\n",
    "global ind\n",
    "ind=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3c20f4a-8a37-4cde-ac5c-6858dd6fa70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy\",accuracy_score(Y_test,Y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23da0b6-bba6-40b8-bb4e-1fce0622204e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d503f6-c2ab-4515-8cf0-5cb087949e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
